{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yannick\n",
    "\n",
    "\"\"\"\n",
    "- Read csv\n",
    "- Format the data ( all str in float)\n",
    "- Balance analysis (ratio % turn % no turn)\n",
    "\n",
    "Result pd.DataFrame 100% float  (N lines M columns)+N Churn\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Julien\n",
    "\n",
    "\"\"\"\n",
    "- y = 1 if churn 0 if no churn (list of N values)\n",
    "- x = [[input_1, input_2, ...], [input_1, input_2, ...], [input_1, input_2, ...], ...] (list of N list of M values)\n",
    "\n",
    "Suffle data order (x and y at the same time), 80% train 20% test, => sklearn function\n",
    "- y_train, y_test \n",
    "- x_train, y_test \n",
    "\n",
    "Scale data => sklearn function\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "scaled_x_train = scaler.transform(x_train)\n",
    "scaled_x_test = scaler.transform(x_trian)\n",
    "\n",
    "pca = PCA(n_components=self.n_pca)\n",
    "pca.fit(scaled_x_train)\n",
    "input_x_train = pca.transform(scaled_x_train)\n",
    "input_x_test = pca.transform(scaled_x_test)\n",
    "\n",
    "-plot pca result for train and an other one for test\n",
    "\n",
    "y_for_plot = np.squeeze(y_train)\n",
    "        cdict = {0: 'red', 1: 'blue'}\n",
    "\n",
    "        if plot:\n",
    "            for i in [[0, 1], [0, 2], [0, 3], [1, 2], [1, 3], [2, 3]]:\n",
    "                p1 = np.squeeze(scaled_x_train[:, i[0]])\n",
    "                p2 = np.squeeze(scaled_x_train[:, i[1]])\n",
    "                fig, ax = plt.subplots()\n",
    "                fig.suptitle(\"P%i vs P%i\" % (i[0], i[1]))\n",
    "                for g in np.unique(y_for_plot):\n",
    "                    ix = np.where(y_for_plot == g)\n",
    "                    ax.scatter(p1[ix[0]], p2[ix[0]], c=cdict[g], label=g, s=3)\n",
    "                ax.legend()\n",
    "                plt.show()\n",
    "                \n",
    "Result input_x_train ([[input_1, input_2, ...], [input_1, input_2, ...], [input_1, input_2, ...], ...]),\n",
    "       y_train [y1, y2, ..., yN],\n",
    "       input_x_test ([[input_1, input_2, ...], [input_1, input_2, ...], [input_1, input_2, ...], ...]),\n",
    "       y_test [y1, y2, ..., yN]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cedric Benoit\n",
    "\n",
    "\"\"\"\n",
    "Train\n",
    "Test\n",
    "Analyze results for best parameters\n",
    "\n",
    "Result y, y_pred\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gab\n",
    "\n",
    "def reslut_analysis(y: np.ndarray, y_pred: : np.ndarray):\n",
    "    # Accuracy\n",
    "    # Confusion matrix\n",
    "    # .... (Corrige)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
